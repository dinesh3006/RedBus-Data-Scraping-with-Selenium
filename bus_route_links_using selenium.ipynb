{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Links:\n",
    "            #--->Successfully scrape a minimum of 10 Government State Bus Transport data from Redbus website using Selenium. \n",
    "            #--->Also include the private bus information for the selected routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_links=[\"https://www.redbus.in/online-booking/apsrtc\",\n",
    "             \"https://www.redbus.in/online-booking/tsrtc\",\n",
    "             \"https://www.redbus.in/online-booking/ksrtc-kerala\",\n",
    "             \"https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc\",\n",
    "             \"https://www.redbus.in/online-booking/wbtc-ctc\",\n",
    "             \"https://www.redbus.in/online-booking/bihar-state-road-transport-corporation-bsrtc\",\n",
    "             \"https://www.redbus.in/online-booking/hrtc\",\n",
    "             \"https://www.redbus.in/online-booking/pepsu-punjab\",\n",
    "             \"https://www.redbus.in/online-booking/astc\",\n",
    "             \"https://www.redbus.in/online-booking/kaac-transport\"            \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# APSRTC Bus Routes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome()  # Initialize the Chrome driver\n",
    "time.sleep(3)  # Wait for the browser to initialize\n",
    "driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "# Scroll down to the first element to click\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/div[1]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "time.sleep(3)  # Wait for the new page to load\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "APSRTC_State = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until all route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                bus_route_name_element = element.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[2]/div[1]/a')\n",
    "                bus_route_name = bus_route_name_element.text\n",
    "                APSRTC_State.append((bus_route_name, href))\n",
    "\n",
    "        # Check for the next page tab\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Output the collected APSRTC State routes\n",
    "for route in APSRTC_State:\n",
    "    Route_APSRTC, link_APSRTC = route\n",
    "    print(f\"Bus Routes Name: {Route_APSRTC}, Bus Routes Link: {link_APSRTC}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the APSRTC_State list\n",
    "df_APSRTC= pd.DataFrame(APSRTC_State, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_APSRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_APSRTC.csv'\n",
    "df_APSRTC.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# TSRTC Bus Routes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome()  # Initialize the Chrome driver\n",
    "driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "# Scroll to the element identified by the given XPath and click it\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/div[2]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "time.sleep(3)  # Wait for the bus routes section to load\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "TSRTC_State = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until all route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                bus_route_name_element = element.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[2]/div[1]/a')\n",
    "                bus_route_name = bus_route_name_element.text\n",
    "                TSRTC_State.append((bus_route_name, href))\n",
    "\n",
    "        # Scroll down until just above the page navigation controls\n",
    "        page_path_element = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs')  # Adjust selector if needed\n",
    "        actions.move_to_element(page_path_element).perform()\n",
    "        time.sleep(2)  # Wait to ensure all elements have loaded\n",
    "\n",
    "        # Find the next page tab if it exists\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Output the collected TSRTC State routes\n",
    "for route in TSRTC_State:\n",
    "    Route_TSRTC, link_TSRTC = route\n",
    "    print(f\"Bus Routes Name: {Route_TSRTC}, Bus Routes Link: {link_TSRTC}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the TSRTC_State list\n",
    "df_TSRTC= pd.DataFrame(TSRTC_State, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_TSRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_TSRTC.csv'\n",
    "df_TSRTC.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# KSRTC (Kerala) Bus Routes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome()  # Initialize the Chrome driver\n",
    "time.sleep(3)  # Wait for the browser to initialize\n",
    "#driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "# Scroll down to the first element to click\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/div[3]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "time.sleep(3)  # Wait for the new page to load\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "KSRTC_Kerala = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until all route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                bus_route_name_element = element.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[2]/div[1]/a')\n",
    "                bus_route_name = bus_route_name_element.text\n",
    "                KSRTC_Kerala.append((bus_route_name, href))\n",
    "\n",
    "        # Check for the next page tab\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Output the collected KSRTC (Kerala) routes\n",
    "for route in KSRTC_Kerala:\n",
    "    Route_KSRTC, link_KSRTC = route\n",
    "    print(f\"Bus Routes Name: {Route_KSRTC}, Bus Routes Link: {link_KSRTC}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the KSRTC_Kerala list\n",
    "df_KSRTC_Kerala= pd.DataFrame(KSRTC_Kerala, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_KSRTC_Kerala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_KSRTC_Kerala.csv'\n",
    "df_KSRTC_Kerala.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# South Bengal State Transport Corporation (SBSTC) Bus Routes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(3)  # Wait for the browser to initialize\n",
    "driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "# Scroll down to the span element identified by the XPath\n",
    "span_element = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/span/span/i'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(span_element).perform()\n",
    "\n",
    "# Wait until the span element is clickable and then click it\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/span/span/i')))\n",
    "span_element.click()\n",
    "\n",
    "time.sleep(3)  # Wait for the click action to be processed\n",
    "\n",
    "# Scroll to the next specified element and click it\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/div[4]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "\n",
    "time.sleep(3)  # Wait for the click action to be processed\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "SBSTC_State = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until all route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            # Scroll to each element\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            # Gather the href link\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                # Use the text of the a.route element as the bus route name\n",
    "                bus_route_name = element.text.strip()\n",
    "                SBSTC_State.append((bus_route_name, href))\n",
    "\n",
    "        # Scroll down until just above the page navigation controls\n",
    "        page_path_element = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs')\n",
    "        actions.move_to_element(page_path_element).perform()\n",
    "        time.sleep(2)  # Wait to ensure all elements have loaded\n",
    "\n",
    "        # Find the next page tab if it exists\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                # Scroll to the next page tab and click it\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Print all gathered bus route names and their corresponding links\n",
    "# Output the collected SBSTC_State routes\n",
    "for route in SBSTC_State:\n",
    "    Route_SBSTC_State, link_SBSTC_State = route\n",
    "    print(f\"Bus Routes Name: {Route_SBSTC_State}, Bus Routes Link: {link_SBSTC_State}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the SBSTC_State list\n",
    "df_SBSTC_State= pd.DataFrame(SBSTC_State, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_SBSTC_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_SBSTC_State.csv'\n",
    "df_SBSTC_State.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# West bengal transport corporation Bus Routes** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "\n",
    "# Scroll down to the span element identified by the XPath\n",
    "span_element = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/span/span/i'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(span_element).perform()\n",
    "\n",
    "# Wait until the span element is clickable and then click it\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/span/span/i')))\n",
    "span_element.click()\n",
    "\n",
    "time.sleep(3)  # Wait for the click action to be processed\n",
    "\n",
    "# Scroll to the next specified element and click it\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/div[5]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "\n",
    "time.sleep(3)  # Wait for the click action to be processed\n",
    "\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "WBSTC_State = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until all route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                bus_route_name_element = driver.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[2]/div[1]/a')\n",
    "                bus_route_name = bus_route_name_element.text\n",
    "                WBSTC_State.append((bus_route_name, href))\n",
    "\n",
    "        # Check for the next page tab\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Output the collected WBSTC_State routes\n",
    "for route in WBSTC_State:\n",
    "    Route_WBSTC_State, link_WBSTC_State = route\n",
    "    print(f\"Bus Routes Name: {Route_WBSTC_State}, Bus Routes Link: {link_WBSTC_State}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the WBSTC_State list\n",
    "df_WBSTC_State= pd.DataFrame(WBSTC_State, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_WBSTC_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_WBSTC_State.csv'\n",
    "df_WBSTC_State.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# Bihar state road transport corporation (BSRTC) Bus Routes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome()  # Initialize the Chrome driver\n",
    "time.sleep(3)  # Wait for the browser to initialize\n",
    "driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "# Scroll down to the span element identified by the XPath\n",
    "span_element = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/span/span'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(span_element).perform()\n",
    "\n",
    "# Click the right side of the span element twice\n",
    "for _ in range(2):\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/span/span/i')))\n",
    "    span_element.click()\n",
    "    time.sleep(1)  # Wait a bit before the next click\n",
    "\n",
    "# Wait for the click action to be processed\n",
    "time.sleep(3)\n",
    "\n",
    "# Scroll to the next specified element and click it\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/div[6]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "\n",
    "time.sleep(3)  # Wait for the click action to be processed\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "BSRTC_routes = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until all route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                bus_route_name_element = element.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[2]/div[1]/a')\n",
    "                bus_route_name = bus_route_name_element.text\n",
    "                BSRTC_routes.append((bus_route_name, href))\n",
    "\n",
    "        # Check for the next page tab\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Output the collected BSRTC routes\n",
    "for route in BSRTC_routes:\n",
    "    Route_BSRTC, link_BSRTC = route\n",
    "    print(f\"Bus Route Name: {Route_BSRTC}, Bus Route Link: {link_BSRTC}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the BSRTC_routes list\n",
    "df_BSRTC_routes= pd.DataFrame(BSRTC_routes, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_BSRTC_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_BSRTC_routes.csv'\n",
    "df_BSRTC_routes.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# HRTC Bus Routes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(3)  # Wait for the browser to initialize\n",
    "driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "# Scroll down to the span element identified by the XPath\n",
    "span_element = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/span/span'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(span_element).perform()\n",
    "\n",
    "# Click the right side of the span element twice\n",
    "for _ in range(2):\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/span/span/i')))\n",
    "    span_element.click()\n",
    "    time.sleep(1)  # Wait a bit before the next click\n",
    "\n",
    "# Wait for the click action to be processed\n",
    "time.sleep(3)\n",
    "\n",
    "# Scroll to the next specified element and click it\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/div[7]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "time.sleep(3)  # Wait for the click action to be processed\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "HRTC_State = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until a.route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                bus_route_name_element = element.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[2]/div[1]/a')\n",
    "                bus_route_name = bus_route_name_element.text\n",
    "                HRTC_State.append((bus_route_name, href))\n",
    "\n",
    "        # Check for the next page tab\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Output the collected HRTC State routes\n",
    "for route in HRTC_State:\n",
    "    Route_HRTC_State, link_HRTC_State = route\n",
    "    print(f\"Bus Route Name: {Route_HRTC_State}, Bus Route Link: {link_HRTC_State}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the HRTC_State list\n",
    "df_HRTC_State= pd.DataFrame(HRTC_State, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_HRTC_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_HRTC_State.csv'\n",
    "df_HRTC_State.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# PEPSU (Punjab) Bus Routes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome()  # Initialize the Chrome driver\n",
    "time.sleep(3)  # Wait for the browser to initialize\n",
    "driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "# Scroll down to the span element identified by the XPath\n",
    "span_element = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/span/span'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(span_element).perform()\n",
    "\n",
    "# Click the right side of the span element three times\n",
    "for _ in range(3):\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/span/span/i')))\n",
    "    span_element.click()\n",
    "    time.sleep(1)  # Wait a bit before the next click\n",
    "\n",
    "# Wait for the click action to be processed\n",
    "time.sleep(3)\n",
    "\n",
    "# Scroll to the next specified element and click it\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/div[9]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "\n",
    "time.sleep(3)  # Wait for the click action to be processed\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "PEPSU = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until all route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                bus_route_name_element = element.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[2]/div[1]/a')\n",
    "                bus_route_name = bus_route_name_element.text\n",
    "                PEPSU.append((bus_route_name, href))\n",
    "\n",
    "        # Check for the next page tab\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Output the collected PEPSU routes with links converted to text\n",
    "for route in PEPSU:\n",
    "    Route_PEPSU, link_PEPSU = route\n",
    "    print(f\"Bus Route Name: {Route_PEPSU}, Bus Route Link: {link_PEPSU}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the PEPSU list\n",
    "df_PEPSU= pd.DataFrame(PEPSU, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_PEPSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_PEPSU.csv'\n",
    "df_PEPSU.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# Assam State Transport Corporation (ASTC) Bus Routes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome()  # Initialize the Chrome driver\n",
    "time.sleep(3)  # Wait for the browser to initialize\n",
    "driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "# Scroll down to the span element identified by the XPath\n",
    "span_element = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/span/span'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(span_element).perform()\n",
    "\n",
    "# Click the right side of the span element three times\n",
    "for _ in range(3):\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/span/span/i')))\n",
    "    span_element.click()\n",
    "    time.sleep(1)  # Wait a bit before the next click\n",
    "\n",
    "# Wait for the click action to be processed\n",
    "time.sleep(3)\n",
    "\n",
    "# Scroll to the next specified element and click it\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/div[10]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "\n",
    "time.sleep(3)  # Wait for the click action to be processed\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "ASTC_State = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until all a.route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                bus_route_name_element = element.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[2]/div[1]/a')\n",
    "                bus_route_name = bus_route_name_element.text\n",
    "                ASTC_State.append((bus_route_name, href))\n",
    "\n",
    "        # Check for the next page tab\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Output the collected ASTC State routes\n",
    "for route in ASTC_State:\n",
    "    Route_ASTC, link_ASTC = route\n",
    "    print(f\"Bus Route Name: {Route_ASTC}, Bus Route Link: {link_ASTC}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the ASTC_State list\n",
    "df_ASTC_State= pd.DataFrame(ASTC_State, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_ASTC_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_ASTC_State.csv'\n",
    "df_ASTC_State.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# KAAC TRANSPORT Bus Routes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome()  # Initialize the Chrome driver\n",
    "time.sleep(3)  # Wait for the browser to initialize\n",
    "driver.maximize_window()\n",
    "driver.get('http://www.google.com/')\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Search for the RedBus website\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys('https://www.redbus.in/')\n",
    "search_box.submit()\n",
    "time.sleep(3)  # Wait for search results to load\n",
    "\n",
    "# Click on the first search result\n",
    "search_result = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"rso\"]/div[1]/div/div/div/div/div/div/div/div[1]/div/span/a/h3'))\n",
    ")\n",
    "search_result.click()\n",
    "time.sleep(3)  # Wait for the RedBus homepage to load\n",
    "\n",
    "# Scroll down to the span element identified by the XPath\n",
    "span_element = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/span/span'))\n",
    ")\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(span_element).perform()\n",
    "\n",
    "# Click the right side of the span element five times\n",
    "for _ in range(5):\n",
    "    right_click_element = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"Carousel\"]/span/span/i')))\n",
    "    span_element.click()\n",
    "    time.sleep(1)  # Wait a bit before the next click\n",
    "\n",
    "# Wait for the click action to be processed\n",
    "time.sleep(3)\n",
    "\n",
    "# Scroll to the next specified element and click it\n",
    "element_to_click = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Carousel\"]/div[14]/div[1]/div[1]/div[2]/div[1]/div[1]'))\n",
    ")\n",
    "actions.move_to_element(element_to_click).perform()\n",
    "element_to_click.click()\n",
    "\n",
    "time.sleep(3)  # Wait for the click action to be processed\n",
    "\n",
    "\n",
    "# List to store gathered links and their corresponding bus route names\n",
    "KAAC_TRANSPORT = []\n",
    "\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait until all route elements are present on the page\n",
    "        route_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.route'))\n",
    "        )\n",
    "\n",
    "        # Scroll down slowly and gather href links and bus route names\n",
    "        for element in route_elements:\n",
    "            actions.move_to_element(element).perform()\n",
    "            time.sleep(0.5)  # Adjust the sleep time for a smoother scroll\n",
    "\n",
    "            href = element.get_attribute('href')\n",
    "            if href:\n",
    "                bus_route_name_element = element.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[2]/div[1]/a')\n",
    "                bus_route_name = bus_route_name_element.text\n",
    "                KAAC_TRANSPORT.append((bus_route_name, href))\n",
    "\n",
    "        # Check for the next page tab\n",
    "        try:\n",
    "            active_page = driver.find_element(By.CSS_SELECTOR, 'div.DC_117_pageTabs.DC_117_pageActive')\n",
    "            next_page_tab = active_page.find_element(By.XPATH, 'following-sibling::div[@class=\"DC_117_pageTabs \"]')\n",
    "\n",
    "            if next_page_tab:\n",
    "                actions.move_to_element(next_page_tab).click().perform()\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                page_number += 1\n",
    "            else:\n",
    "                print(f\"No more pages to paginate at step {page_number}\")\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {page_number}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pagination: {e}\")\n",
    "        break\n",
    "\n",
    "# Output the collected KAAC TRANSPORT routes with the link converted to text format\n",
    "for route in KAAC_TRANSPORT:\n",
    "    Route_KAAC_TRANSPORT, link_KAAC_TRANSPORT = route\n",
    "    print(f\"Bus Route Name: {Route_KAAC_TRANSPORT}, Route Text: {link_KAAC_TRANSPORT}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the KAAC_TRANSPORT list\n",
    "df_KAAC_TRANSPORT= pd.DataFrame(KAAC_TRANSPORT, columns=['Bus Routes Name', 'Bus Routes Link'])\n",
    "df_KAAC_TRANSPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "path = 'C:\\\\Users\\\\hp\\\\OneDrive\\\\Pictures\\\\guvi certificates\\\\web-scraping using selenium\\\\df_KAAC_TRANSPORT.csv'\n",
    "df_KAAC_TRANSPORT.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
